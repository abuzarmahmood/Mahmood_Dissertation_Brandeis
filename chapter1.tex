\begin{refsection}

\chapter{Introduction}

\section{A Brief Introduction to Neural Architectures}
With the advent and advance of artificial neural networks, our understanding of the role neural architectures play in learning and information processing continues to progress1–3. Primarily, the fact that connectivity between units of the neural network can be trained and tweaked to approximate arbitrary functions4. However, the “architecture” of the network is known to strongly constrain how well the network can learn different functions and fit to different kinds of data5–7. Such that, networks which are purely feedforward perform well on datasets containing independently distributed data, but perform relatively poorly on data which is sequentially correlated (any sort of time-series data, e.g. audio and video data, and neural and behavioral responses)8,9. Such data, which are generated from dynamical processes (such that the current datapoint influences the next datapoint to come) are well modelled using neural networks which are allowed to re-intake their output for the current datapoint, as an input for the next datapoint. Such recurrent networks proved a breakthrough for modelling many kinds of timeseries data10,11. Hence, it is not surprising that since our lived experience almost exclusively involves dynamic input (none of our sensory inputs are naturally point processes), that our brains contain strongly recurrent connectivity12–15. 
Despite this fact, much previous work has been devoted to studying the feedforward aspects of processing in the brain16,17, a view that strongly persists today; however, the general applicability of this viewpoint is now being challenged, and more research is recognizing the degree to which such recurrent connectivity is utilized in the brain. In the brain, we find recurrent connections not only within single brain regions (a circuit modulating itself), but also between multiple brain regions (modulating each other in a loop)18–20.

\section{Recurrent connectivity in the brain, and its role in generating neural dynamics}
Recurrent connectivity of a network allows the network to actively modulate its state for future input to alter the output it produces, hence giving it “memory”. In this manner, the output of the network to the same input is conditioned upon what came before, providing it with a more expressive space of responses, e.g. what you want for dessert is likely influenced by what you had for the main course, however, this is something that your brain needs to remember11. One might argue that a feedforward neural network can be trained to accept the previous state as an input, and therefore consider that during its processing. This is certainly true if there was an external “memory store” that was keeping track of previous states; however, by rolling these two features into the same network, we return to a recurrent neural network. This modulation occurs at differing timescales depending on the nature of the task at hand, and (as we will see later) is also (understandably) modulated by signals from the body, again at varying timescales21–24.

\subsection{Behavioral and Neural Dynamics Timescales as a spectrum}
The work presented in this thesis will primarily focus on short-scale (milliseconds to seconds) and the long-scale (tens of minutes to hours) dynamics, largely ignoring the “mesoscale” dynamics (tens of seconds to minutes) . However, it is vital to recognize that these categorizations are arbitrary, and behavioral and (concomitantly) neural activity timescales create a spectrum, and generally operate within a hierarchy, e.g., taste responses to a single taste delivery (with changes happening over hundreds of milliseconds) are embedded within and modulated by body-states (which change over tens of minutes to hours). There is nothing particularly special about behavior and neural responses in this context either, any system capable of performing “complex” tasks will exhibit hierarchies over temporal scales (e.g. a microprocessor25). And to take it a step further, such hierarchies of scale are not limited to temporal dynamics either, many processes display spatio-temporal hierarchies26–33. Hence, we should not be surprised, that organisms and neural networks, in order to execute “meaningful” (or at least, complex structured) tasks show spatio-temporal interactions at multiple scales, where this multi-scale organization is directly linked to the information-processing capacity of the system34,35.  

\subsection{Short-scale (milliseconds to seconds) neural dynamics}
The first brand of modulation, recent history dependence, is robustly seen in many forms of sensory processing. In this thesis, the discussion will almost exclusively involve gustatory processing36, however, similar dynamics have long been recognized in vision37, audition38, and decision-making39. Within the gustatory cortex (GC), we see that neural responses to a tastant (which although, is delivered almost instantaneously, considering behavioral timescales, nonetheless, persists in the mouth for a much longer time and evokes similarly long dynamic responses in the brain) consist of a sequence of “epochs” or states, each with varying neural responses and the information contained therein. 
The bulk of investigation into this unfolding response has been in GC during the period from stimulus delivery into the mouth, lasting until the rodent decides to either spit or swallow the tastant, a period lasting roughly 1.5 seconds40–42. During this time, the response can be subjectively classified into periods of “Detection” (0-250ms post-stimulus), “Identity” (250-750ms post-stimulus), and “Palatability” (750-1250ms post-stimulus). The Detection period is characterized by a large change in single-neuron responses with little taste-specific modulation. Taste-specificity in the neural response first appears during the Identity epoch where single neuron responses begin to differentiate between tastants, but as of yet, do not provide much “emotional” information about the perception of the taste. Following this, during the Palatability epoch, the system shifts to exhibiting the hedonic value of the tastant delivered during the Palatability epoch. While the process of the circuit following the behavioral response is yet to be studied, one may speculate that is involved learning or meta-cognition43,44. Hence, the same circuit behaves differently at different timepoints, and this difference in behavior is not simply at the neural response level, but seemingly is a “symptom” of a change in the “mechanism” of the circuit45–47, as we shall see later.
GC, however, is not exceptional in exhibiting these dynamics, and we see similar changes in much of the taste circuit48–52, although the exact nature of the epochs (the encoded information) is different depending on where you look, and may serve as a clue to tease apart the role that particular region plays in taste processing. More interestingly, these shared dynamics suggest that GC is not working alone, and that these regions are in cahoots with each other to carry out this processing. There is still an argument to be made that such dynamics may be produced using a feedforward network that is responding to variation in oromotor movements, and while there hasn’t been a direct test to challenge this assertion (yet), there are various lines of evidence suggesting that is unlikely to be the case. Firstly, the kind of non-linear dynamics that we observe in GC are unlikely to be generated using feedforward networks (refs). Next, we know that the relationship between these brain regions changes over time (more on this later), something unlikely to happen without recurrence. Furthermore, there is abundant recurrent connectivity between different nodes of the taste circuit, and although the role of this circuitry is yet to be explored, it is unlikely that is remains unutilized in computation53–55. Penultimately, we know that changes in GC neural responses precede behavioral changes, and therefore cannot simply be a response to oromotor activity56. And finally, the epochs that we observe in GC neural responses are aptly described as states in a putative attractor network57,58 (discussed below), which strongly require recurrent functional connectivity between its nodes (refs).
Attractor networks exhibit responses which remain stable at short timescales, rather than changing continuously, and hence are well described using Hidden Markov Models (HMM)59–62. Much work from the lab has focused on this interesting property of GC responses (although such responses are seen elsewhere too, see 63–65). Even more peculiar is the fact that, on a single-trial basis, the onset of GC epochs (modelled using states in an HMM) is variable. This finding, however, is appealingly explained using attractor networks operating in a noisy regime, and can be further shown to operate more efficiently in the presence of noise (a ubiquitous phenomenon in all biological systems) than other models of biological neural networks57,58.
However, one may ask how a system with recurrent connectivity (where the activity in the previous timestep modulates the next timestep) can “choose” to change its response at certain timepoints yet hold it at a constant value at others, seemingly ignoring history. The answer to this question, again, lies in the generation of attractors via recurrence and nonlinearity present in these networks66. Furthermore, while this has yet to be studied more thoroughly in the context of taste, it has been shown that other systems show intra-attractor dynamics, i.e. the system is not completely “still” once it is within an attractor (as one may expect in noisy systems), that history dependence and dynamics still guide the evolution of the system’s trajectory, however, on a larger scale, the activity of the network seems relatively “constant”67,68.

\subsection{Long-scale (minutes to hours) neural dynamics}
The second brand of modulation we will discuss involves long lasting physiological and neural states69,70. Although the origin of these states is certainly not the same, their effect on neural responses can be jointly discussed. Examples of such states include sickness71,72, expectation/attention73,74, sleep/unconsciousness vs awake75–77, and response to different environments/contexts20,78–80.
Trivially, such longer states are a necessity for organisms to interact appropriately with the environment i.e. longer-scale dynamics are dictated by demands from longer-scale processes e.g. eating vs. exercising will require different kinds of processing and hence will elicit different mental states. It has been shown that people will psychological disorders exhibit changes in the dynamics of long-scale brain states81,82, however, these studies are purely phenomenological and it is not clear which way the arrow of causality points in these cases.
While short-scaled dynamics (up to seconds) are governed by the dynamics of flow of activity through networks and emergent phenomena which influence dynamics on timescales longer than synaptic propagation and ion channel time-constants (such as attractors), the influence of these mechanisms does not scale to minutes or hours and entirely different mechanisms are used to control dynamics in the long-term. Long-term dynamics are usually wrought by synaptic plasticity, in collaboration with the influence of neuromodulators83–88. While discussion of the mechanisms of long-term dynamics is limited in this document, it is important to recognize that while dynamics at different timescales may be considered as parametric counterparts for their evoked effects and their role in behavioral and information processing, a neurobiological understanding of these timescales requires looking in different places.

\section{Dynamics of inter-region functional connectivity}
While artificial neural networks (ANNs) have played a paramount role in improving our understanding of how the brain processes information, these networks have an important shortcoming for understanding how the brain - as a physical object - processes information, they have no notion of physical space or time. While ANNs have provided analogs for how transformations can occur along layers of neurons 9,89, they do not model the fact that communication between neurons in the brain is 1) governed by highly structured connections which create pathways of information flow, and 2) that information flow in the brain is not instantaneous. Both these facts mean that as opposed to ANNs (where activation patterns are largely random) we observe highly structured and widely variable patterns of activation across the brain, and underlying these patterns are dynamic “functional” connections. 

What further complicates the study of these patterns is that while the physical connections constrain the possible motifs of communication between brain regions (a region cannot influence another if there isn’t a direct or indirect connection between them), however, the “connectome” does not by itself tell us the strength and directionality of flow of information at any given moment. The strength and directionality of these “functional” connections are not only determined by the presence of inter-areal connections, but also by interactions of the strength of intra-region connectivity vs inter-region connectivity 90–92.

While the speed of spread of activity in the brain is a biological “limit” that the brain likely has to “work around” (point \#2 above), the pathways of information routing serve a much more ostensible function. Regions in the brain are highly specialized to performing certain tasks, e.g. sensory streams (visual, auditory, gustatory, olfactory) which have little overlap of associated brain regions between them. While this in no way means that they are exclusively limited to performing certain tasks - memory and decision making influence all sensory processing, and many sensory streams collude (visuo-auditory processing, and olfacto-gustatory processing) – it does mean that there are preferred pathways for information to flow depending on the task at hand. The simplest example is in the case of sensory processing e.g. while the perceived sound may change what we visually perceive (and vice versa), auditory processing regions cannot “stand in” for visual processing, and when we hear a sound, there is a reliable set of brain regions activated in response to the sound which are not activated to nearly the same extent for other sensory modalities. Hence, one may (rightfully) expect connectivity and inter-region communication to be highly structured, such that the brain regions recruited for a certain task are pretty “sparse” (albeit in a weak sense of the word). However, since the brain shows “small-world” connectivity, such that the degrees of separation (or hops) between brain region are quite small, there is much variation to this highly structured communication and much room for flexibility and nuance in inter-region communication via indirect connections; and in experimental recordings, one finds many “unexpected” regions to also be active for tasks. Again, while these patterns of activity and communication can be similarly studied at short- and long- timescales, the underlying mechanisms for generating these patterns are different depending on the specific timescale one is focused on.
While it is agreed that communication between brain regions is required for complex processing (refs showing breakdown of processing with messing with connections, all JY papers), the “mode” of this communication, and how communication is measured varies widely. Grouping modes of communication into two broad camps, one may expect sequential/hierarchical information flow or parallel processing. In the sequential/hierarchical group, information flow/transformation of information happens in a linear fashion, such that each sequential neural layer/brain region contains more “complex” representations. This mode is closely related to how many ANNs operate. As a specific example, deep convolutional neural networks (CNNs) attempt to model (and in many cases, succeed at modelling) the flow of information along the visual stream, where the first layer in a CNN (similar to V1) represents filters with simple shapes. These filters are nonlinearly combined in subsequent layers to model increasingly complex shapes, as one finds going from V1 to V4/area MT and then further on to the parietal cortex. While this bottom-up model accounts well for many aspects of sensory processing, it does not provide a complete account. There has been much recent work examining the role of simultaneous top-down influences in sensory processing to focus/shape neural activity at the level of primary sensory cortices. However, while the existence of bottom-up and top-down streams is widely acknowledged, they are still treated separately and the real-time, dynamic interaction between them (parallel processing) is still not being investigated. This view of parallel processing adds another level of complexity, investigating how the system collectively evolves over time (across all levels of the “hierarchy”)(refs). Hence, the feedforward transformation to generate for complex statistics is only one aspect of the process, while the collective evolution of neural population codes over time is the “primary” process through which the network performs the requisite transformations.
Distinction between these “modes”, however, is contentious as it is biased by the tools and “signals” one uses to measure communication. Currently, the state-of-the-art of measuring communication between brain regions is quantifying the similarity of signals recorded from different brain regions. Previous investigations have indexed communication at the level of intra-cranial signals as: spike trains, firing rates, local field potentials; and extra-cranial signal as: EEG and BOLD signals. Arguably, each of these signals is a proxy for communication at difference spatio-temporal scales. Spike trains are considered to represent quick (tens of milliseconds) timescale communication happening between directly connected neurons. Firing rates are considered to show communication at a scale of hundreds of milliseconds to seconds, between neural populations. While LFPs are considered to be a proxy for communication between whole brain regions, again at a scale of hundreds of milliseconds to seconds, going up to minutes and hours. Extra-cranial signals as EEG and BOLD are necessarily limited in spatial resolution due to the technologies they utilize, but are very different in their temporal scale. As mentioned above, the primary way these signals are utilized to quantify communication is by calculating the similarity between signals, or attempt inferring the direction of causality using the degree of predictability of one signal using the other. However, these methods generally suffer from trial-averaging (under the provably incorrect assumption that repeated neural evoked response are temporally identical), and assuming slow changes in neural activity. This necessitates the investigation of coherence metrics which account for trial-to-trial variability, and can model changes happening at small timescales, as presented in the second paper here.

\section{Summary}
In the following articles, this thesis will explore modulation of gustatory processing on long timescales (tens of minutes) due to change in body states (sickness), short timescale (hundreds of milliseconds) dynamics and coherence between brain regions for the purpose of taste processing while performing a comparison of information gleaned using “canonical” and new methodologies to assess communication (which will suggest that processing in the taste circuit is not strictly hierarchical, as previously thought), and conclude with a discussion that cautions neuroscientists to not assume the function of neurons without considering the temporal dynamics and context in which the response of that neuron is embedded.

\printbibliography[title={References}]
\end{refsection}